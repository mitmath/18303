% !TEX TS-program = xelatex
% !TEX encoding = UTF-8 Unicode
\input{../structure.tex}

\title{Spectral methods and the weak formulation}
\subtitle{Working with bases of functions}
\date{25/3/2021}
\date{}
%\author{18.303 Linear Partial Differential Equations: Analysis and Numerics}
\institute{18.303 Linear Partial Differential Equations: Analysis and Numerics}
\titlegraphic{\hfill\includegraphics[height=2em]{../MIT-logo.pdf}}

\begin{document}
	
	\maketitle
	
%	\begin{frame}{Table of contents}
%		\setbeamertemplate{section in toc}[sections numbered]
%		\tableofcontents%[hideallsubsections]
%	\end{frame}
	
\begin{frame}{Introduction}
	\begin{itemize}[<+->]
		\item The main idea of spectral methods is to represent the functions we work with in a given basis
		\item We choose a basis that has a sparse inner product matrix $ \Phi_{i,j} = \iprod{\phi_i}{\phi_j} $, most often just a diagonal $ \Phi_{i,j} = a_i \delta_{i}^{j} $
		\item Furthermore, we want our differential operations to have a sparse representation in this basis i.e. the matrix $ L $ defined by $ \iprod{\phi_i}{\opone \phi_j} =  L_{i,j} $ has to be sparse
		\item This far we have used the eigenbasis, which always gives a diagonal $ L $ but this is not always possible or easy to do
		\item This is the case with difficult boundary conditions and nonlinear (partial) differential equations
		\item The upside of spectral methods is that they many times converge \emph{exponentially} to the solution when the data we are dealing with is smooth enough
		\item This amounts to high efficiency since the derivatives are evaluated accurately even with a small number of modes (the basis needs to be truncated for computations)
	\end{itemize}
\end{frame}

\begin{frame}{Introduction}
	Many of the bases arise as the eigenbases of the Laplacian $ \Delta $. Some examples include
	\begin{itemize}[<+->]
		\item Sine and cosine bases for 0 boundaries and periodic domains
		\item Bessel functions for cylindrical domains
		\item Spherical harmonics for a Laplacian on the 2-sphere
	\end{itemize}

	There are also a bunch of polynomial bases e.g.
	\begin{itemize}[<+->]
		\item Chebyshev and Legendre polynomials for a closed interval $ x \in (-1,1) $
		\item Laguerre polynomials for $ x \in \R_+ $
		\item Hermite polynomials for $ x \in \R $
	\end{itemize}
\end{frame}

\begin{frame}{Weak formulation}
	This far we have considered differential equations
	\[ \opone u (\vx) = f(\vx), \]
	on some domain $ x \in \Omega $ with boundary conditions 
	\[ \optwo u  = b(\vx) \]
	on the boundary $ x \in \partial \Omega $. We say that the functions fulfilling the boundary condition are in some vector space $ V $. 
	
	\pause
	The weak formulation states that we can we can write the first equation as
	\[ \iprod{\varphi}{\opone u} = \iprod{\varphi}{f} \]
	for all $ \varphi \in V' $. 
	
	\pause
	The functions $ \varphi $ are \alert{test functions} and it suffices that $ V' = C_0^{\infty} $ i.e. the space of smooth functions (infinitely differentiable) whose all derivatives and values are 0 at the boundary.
\end{frame}

\begin{frame}
	After a lot of mathematical details we can say that the solution to the weak problem agrees almost everywhere (everywhere except possibly at isolated points) to the solution of the original problem. 
	
	\pause
	Let's assume for the time being that we have some basis functions $ \{ \phi_i \} $ that satisfy the boundary conditions. We can approximate both the test functions and the $ u $ in this basis writing 
	\[ u(\vx) = \sum_{j=0}^{N-1} \hat{u}_j \phi_j(\vx), \; \varphi(\vx) = \sum_{i=0}^{N-1} \hat{\varphi}_i \phi_i(\vx).  \]
	
	\pause
	The weak form becomes
	\[ \sum_{i,j =0}^{N-1} \hat{\varphi}_i \hat{u}_j \iprod{\phi_i}{\opone \phi_j} 
	= \sum_{i=0}^{N-1} \hat{\varphi}_i \iprod{\phi_i}{f}
	\]
	for all $ \hat{\varphi}_i $. The only way the equation holds is if
	\[ \sum_{j =0}^{N-1} \hat{u}_j \iprod{\phi_i}{\opone \phi_j} 
	=  \iprod{\phi_i}{f}
	\]
	for all $ i $. We assume here that $ \opone : V_N \to V_N  $ when restricted to just $ N $ modes.
\end{frame}

\begin{frame}
	We write again $ L = \iprod{\phi_i}{\opone \phi_j}  $. This becomes a matrix equation
	\[ L \hat{\vu} = \hat{\fone}, \]
	where $ L $ is some square matrix with dimensions $ N\times N $. 
	
	\pause
	What do we get from solving this equation? \pause The expansion coefficients for $ u $. 
	
	\pause
	This is called the \alert{Galerkin method} for solving a linear PDE. The error of the solution $ \epsilon = u - u_N $ satisfies
	\[ \iprod{\phi_k}{\opone\epsilon } = \iprod{\phi_k}{\opone u } - \iprod{\phi_k}{\opone  u_N}
	= \iprod{\phi_k}{f} - \iprod{\phi_k}{f_N} = 0.
	\]
	
	\pause
	This means that the error lives in the orthogonal space so solving in the truncated space $ V_N $ is the best projection of the solution onto $ V_N \subset V $.
\end{frame}

\begin{frame}
	What if $ L $ is not invertible?
	
	\pause
	This might happen if the operator $ \opone $ maps some basis functions to zero.

	\pause
	The solution is to lift the condition for satisfying the boundary conditions. Then we can fix the coefficients of modes that are in the null space of $ \opone $.
	
	\pause
	This is better illustrated with an example.
\end{frame}

\begin{frame}{Example}
	Let the differential operator be $ \opone = \dd[2]{}{x} $ on the interval $ x \in (-1,1) $ and assume we have $ u(-1) = u_- $ and $ u(1) = u_+ $. Let our basis functions be some polynomials for which the degree of $ \phi_n $ is $ n $. 
	
	\pause
	We calculate the matrix element
	\[ L_{i,j} =  \iprod{\phi_i}{\opone \phi_j}  = \int_{-1}^{1} \phi_i(x) \phi_j''(x) \diff x.     \]
	
	\pause
	\[ L_{i,j}  = \left.\phi_i(x) \phi_j'(x)  \right| _{x=-1}^{1} 
	-\int_{-1}^{1} \phi_i' (x) \phi_j'(x) \diff x.   \]
	
	\pause
	Setting $ j=0 $ chooses the first column of the matrix. Since the degree of $ \phi_0 $ is zero, the matrix elements are zero. This means that we can't solve for the coefficient $ \hat{u}_0 $. 
	
	\pause
	It turns out the Null space of $ L $ has dimension 2. From the boundary conditions we have
	\[ u_- = \sum_{j=0}^{N-1} \hat{u}_j \phi(-1), \; u_+ = \sum_{j=0}^{N-1} \hat{u}_j \phi(1). \]
	Adding these equations solves the coefficients uniquely. 
\end{frame}

\end{document}
