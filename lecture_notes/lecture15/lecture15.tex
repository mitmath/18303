% !TEX TS-program = xelatex
% !TEX encoding = UTF-8 Unicode
\input{../structure.tex}

\title{Functionals and the variational derivative}
\subtitle{Using energies to make sense of PDEs}
\date{25/3/2021}
\date{}
%\author{18.303 Linear Partial Differential Equations: Analysis and Numerics}
\institute{18.303 Linear Partial Differential Equations: Analysis and Numerics}
\titlegraphic{\hfill\includegraphics[height=2em]{../MIT-logo.pdf}}

\begin{document}
	
	\maketitle
	
%	\begin{frame}{Table of contents}
%		\setbeamertemplate{section in toc}[sections numbered]
%		\tableofcontents%[hideallsubsections]
%	\end{frame}

\begin{frame}{Functionals}
	Assume we have a function $ V \ni f: \R^N \to \R $ that takes $ N $-dimensional vectors and maps them to real numbers. 
	
	\pause
	Functionals are a generalization of this concept. Formally we have $ F: V \to \R $. We can write these using an integral as
	\[ F[f] = \int_{\Omega} g(f(\vx), ...)  \diff \vx. \]
	
	\pause
	The function $ g $ can depend not only on $ f(x) $ but it's derivatives (or more generally some linear operators acting on $ f $). 
\end{frame}

\begin{frame}{Example}
	In Pset 2 we had the energy
	\[ H[u,v] = \frac{1}{2} \int_{0}^{1} v(t,x)^2 + u'(t,x)^2 \diff x,  \]
	where $ v = \partial_t u $. 
	
	\pause
	This would be an example of a functional that can be evaluated for any $ u, v \in V $. In this case the function $ g $ depends on the time and the spatial derivatives of $ u $. 
	
	\pause
	Another example:
	consider a graph $ \gamma = \{ (x,f(x)) : x \in (0,1) \} $. The length of the graph (curve) is given by
	\[ L_{\gamma}[f] = \int_{0}^{1} \sqrt{1 + f'(x)^2} \diff x. \]
\end{frame}

\begin{frame}{Derivatives of functions}
	Consider a function $ f: \R^N \to \R $. How can we make sense of the derivative $ \nabla $?
	
	\pause
	We can define the derivative as a directional derivative. We have
	\[ f(\vx + \epsilon \vy) = f(\vx) + \epsilon \vy \cdot \nabla f(\vx) + \BigO(\epsilon^2).   \]
	
	\pause
	We can define the gradient of $ f $ at $ \vx $ by 
	\[ \iprod{\vy}{\nabla f(\vx)} = \vy \cdot \nabla f(\vx)  = \lim_{\epsilon \to 0} \frac{f(\vx + \epsilon \vy) - f(\vx)}{\epsilon} \]
	for all $ \vy \in \R^N $.
	
	\pause
	We can choose $ \vy $ to be some basis vectors $ \hat{\vec{x}}_i $ for $ i = 1, ..., N $ giving us the coordinate representation 
	\[ \nabla f(\vx) = (\partial_{x_1} f(\vx), \partial_{x_2} f(\vx), ... , \partial_{x_N} f(\vx)) . \]
\end{frame}

\begin{frame}{Derivatives of functionals}
	We can generalize the notion of the gradient of a function. Let's define
	\[ \iprod{\phi}{\frac{\delta F[f]}{\delta f}} = \lim_{\epsilon \to 0} \frac{F[f + \epsilon \phi]- F[f]}{\epsilon} = \left( \dd{F[f+\epsilon \phi]}{\epsilon} \right)_{\epsilon = 0} \]
	for all $ \phi \in C_0^\infty $ (the space here is important).
	
	\pause
	In a similar way to a directional derivative, this measures the change of the functional $ F $ at $ f $ in the direction of $ \phi $. 
	
	\pause
	Since the inner product is some integral 
	\[ \iprod{f}{g} = \int_{\Omega} f(\vx) g(\vx) \diff \vx, \]
	we can immediately see that 
	$ \delta F[f]/\delta f $
	is a function (or a distribution). It is called the \alert{variational derivative} or \alert{functional derivative} of $ F $. 
\end{frame}

\begin{frame}{Example}
	Let's consider the same functional as before i.e. 
	\[ H[u,v] = \frac{1}{2} \int_{0}^{1} v(t,x)^2 + u'(t,x)^2 \diff x.  \]
	
	\pause
%	We know that $ u $ (and $ v $) have Dirichlet boundaries i.e. $ u(0) = u(1) = 0 $. 
	Let's calculate
	\[ H[u, v + \epsilon \phi]  = \frac{1}{2} \int_{0}^{1}  (v + \epsilon \phi)^2 + (u')^2  \diff x 
	= \frac{1}{2} \int_{0}^{1} v^2 + (u')^2 \diff x + \frac{1}{2} \int_{0}^1 2 \epsilon \phi v \diff x + \BigO(\epsilon^2).
	\] 
	
	\pause
	We recognize the first term as $ H[u,v] $ giving
	\[ H[u, v + \epsilon \phi] - H[u,v] = \epsilon \int_{0}^1 \phi v \diff x + \BigO(\epsilon^2)
	= \epsilon \iprod{\phi}{v} + \BigO(\epsilon^2).
	\]
	
	\pause
	We can divide by $ \epsilon $ and take the limit giving 
	\[ \iprod{\phi}{\frac{\delta H[u,v]}{\delta v}} :=  \lim_{\epsilon \to 0} \frac{H[u, v + \epsilon \phi] - H[u,v]}{\epsilon}  = \iprod{\phi}{v}.  \]
	
\end{frame}

\begin{frame}
	\[ \iprod{\phi}{\frac{\delta H[u,v]}{\delta v}} :=  \lim_{\epsilon \to 0} \frac{H[u, v + \epsilon \phi] - H[u,v]}{\epsilon}  = \iprod{\phi}{v}.  \]
	
	\pause
	Since this holds for all $ \phi \in C_0^\infty $ we conclude that 
	\[ \frac{\delta H[u,v]}{\delta v} = v \]
	in a weak sense (almost everywhere).
	Note that in practice we collected all the terms proportional to $ \epsilon $. Also, this just gave us the usual derivative of $ v^2/2 $.
\end{frame}

\begin{frame}{Another example}
	Let's define the potential energy part of the above energy as 
	\[ U[u] = \frac{1}{2} \int_{0}^1 u'(x)^2 \diff x.  \]
	
	\pause
	Let's calculate the functional derivative $ \delta U/ \delta u $. We have 
	\[ U[u + \epsilon \phi] = \frac{1}{2}\int_0^1 \left(\partial_x (u + \epsilon \phi)  \right)^2 \diff x  
	= \frac{1}{2} \int_0^1 (u')^2 \diff x + \epsilon  \int_0^1 u' \phi' \diff x + \BigO(\epsilon^2).
	\]
	
	\pause
	Again, we recognize the first part as $ U $ and we have 
	\[ \frac{U[u + \epsilon \phi] - U[u]}{\epsilon} = \int_{0}^1 u' \phi' \diff x + \BigO(\epsilon).  \]
	
\end{frame}

\begin{frame}
	We can use integration by parts for the first term on the right giving
	\[ \int_{0}^1 u' \phi' \diff x = \left(\phi(x) u'(x)  \right)_{x=0}^{1} - \int_{0}^1 \phi u''  \diff x. \]
	
	\pause
	The boundary term evaluates to 0 since $ \phi \in C_0^\infty $. The remaining term can be written as an inner product giving 
	\[ \lim_{\epsilon \to 0}\frac{U[u + \epsilon \phi] - U[u]}{\epsilon} =: \iprod{\phi}{\frac{\delta U}{\delta u}} = -\iprod{\phi}{u''}. \]
	
	\pause
	We conclude that 
	\[ \frac{\delta U[u]}{\delta u} = -u''.\]
	Notice that this is not the usual derivative of the integrand in the functional. 
\end{frame}

\begin{frame}
	In general we have for a functional
	\[ F[f] = \int_\Omega g\left( \left( \prod_i \partial_{x_i}^{n_i} \right) f(\vx) \right) \diff \vx \]
	
	\pause
	\[ \frac{\delta F[f]}{\delta f}(\vx) =  (-1)^{\sum_i n_i} \left(\prod_i \partial_{x_i}^{n_i} \right) \left[  \frac{\partial g}{\partial \left( \prod_i \partial_{x_i}^{n_i} \right) f(\vx) } \right] \]
	and any linear combinations of these.
	
	This formula is somewhat messy so let's give a simpler example. 
\end{frame}

\begin{frame}{Example}
	Let 
	\[ F[f] = \int_\Omega g\left( f(\vx), \nabla f(\vx), \Delta f(\vx) \right) \diff \vx.  \]
	
	\pause
	Now,
	\[ \frac{\delta F}{\delta f}(\vx) = \frac{\partial g}{\partial f(\vx)} - \nabla \cdot \frac{\partial g}{\partial \nabla f(\vx) }  + \Delta \frac{\partial g}{\Delta f(\vx)}.\]
	
	Here 
	\[ \frac{\partial g}{\partial \nabla f(\vx)} = \left(\frac{\partial g}{\partial (\partial_{x_1}f(\vx))},   
	\frac{\partial g}{\partial (\partial_{x_2}f(\vx))}, ..., \frac{\partial g}{\partial (\partial_{x_N}f(\vx))}
	\right)^T. \]
\end{frame}

\begin{frame}{Using variational derivatives}
	Let's use the energy we defined before but in a higher dimension:
	\[ U[u] = \frac{1}{2} \int_\Omega \norm{\nabla u(\vx)}^2 \diff \vx.  \]
	
	\pause
	Calculating the variational derivative gives 
	\[ \frac{\delta U}{\delta u}(\vx) = -\nabla \cdot (\nabla u(\vx)) = -\Delta u(\vx). \]
	Notice that $ \norm{\nabla u(\vx)}^2 = \nabla u(\vx) \cdot \nabla u(\vx) $.
	
	\pause
	We can now define for example the heat equation as 
	\[ \partial_t u(t,\vx) = -\frac{\delta U}{\delta u} (t,\vx) = \Delta u(t,\vx). \]
\end{frame}

\begin{frame}
	Let's look at the change of energy in time $ \partial_t U[u] $. It turns out we can use a sort of chain rule
	\[ \partial_t U[u] = \iprod{\dot{u}}{\frac{\delta U }{\delta u}}. \]
	You can compare this chain rule to a chain rule $ \partial_t g(\vx(t)) = \dot{\vx}\cdot \nabla g(\vx(t)) $.
	
	\pause
	Plugging in the time evolution gives 
	\[ \partial_t U[u] = - \iprod{\frac{\delta U }{\delta u}}{\frac{\delta U }{\delta u}} = -\norm{\frac{\delta U }{\delta u}}^2 \leq 0. \]
	
	\pause
	We immediately see that the energy is non-increasing in time. Notice that for this calculation we only used the fact that 
	\[ \partial_t u(t,\vx) = -\frac{\delta U}{\delta u} \]
	without specifying the form of $ U $. It follows that this is true for \emph{all} dynamics that can be written like this using some functional $ U $!
\end{frame}

\begin{frame}
	For many physical problems we have similar results. E.g. for the wave equation we have
	\[ \begin{split}
		\dot{v} &= -\frac{\delta H}{\delta u} = -\dfrac{\delta U}{\delta u} = \Delta u \\
		\dot{u} &= \frac{\delta H}{\delta v} = v.  
	\end{split} \]
	
	\pause
	It follows that we can replace $ \dot{v} $ by $ \ddot{u} $ in the first equation giving the wave equation. These sort of dynamics will conserve $ H $ in time (you can try this at home) and are called \alert{Hamiltonian} (physics) or \alert{symplectic} (mathematics). 
	
	\pause
	The reason we introduced these techniques is that using such energies as measures for stability and other kind of sanity checks with numerics is extremely helpful, especially for non-linear systems.
\end{frame}

\end{document}
